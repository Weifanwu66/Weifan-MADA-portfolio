{
  "hash": "aa0664ee92646f34bc8e5ea8c39545b3",
  "result": {
    "markdown": "---\ntitle: \"machine learning\"\nauthor: \"Weifan Wu\"\neditor: visual\noutput: html_document\ndate: \"03/28/2023\"\n---\n\n\n### Using machine learning approach to predict `BodyTemp`\n\n##Set up Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ ggplot2 3.4.1     ✔ purrr   1.0.1\n✔ tibble  3.1.8     ✔ dplyr   1.1.0\n✔ tidyr   1.3.0     ✔ stringr 1.5.0\n✔ readr   2.1.3     ✔ forcats 1.0.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(here)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nhere() starts at C:/Users/weifa/OneDrive/Documents/GitKraken/MADA/data analysis/Weifan-MADA-portfolio\n```\n:::\n\n```{.r .cell-code}\nlibrary(skimr)\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.3     ✔ rsample      1.1.1\n✔ dials        1.1.0     ✔ tune         1.0.1\n✔ infer        1.0.4     ✔ workflows    1.1.2\n✔ modeldata    1.1.0     ✔ workflowsets 1.0.0\n✔ parsnip      1.0.3     ✔ yardstick    1.1.0\n✔ recipes      1.0.4     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n```\n:::\n\n```{.r .cell-code}\nlibrary(rpart)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'rpart'\n\nThe following object is masked from 'package:dials':\n\n    prune\n```\n:::\n\n```{.r .cell-code}\nlibrary(glmnet)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Matrix\n\nAttaching package: 'Matrix'\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\nLoaded glmnet 4.1-6\n```\n:::\n\n```{.r .cell-code}\nlibrary(ranger)\nlibrary(vip)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'vip' was built under R version 4.2.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vip'\n\nThe following object is masked from 'package:utils':\n\n    vi\n```\n:::\n\n```{.r .cell-code}\nlibrary(rpart.plot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'rpart.plot' was built under R version 4.2.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(knitr)\n```\n:::\n\n\n## Load data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_location=here::here(\"fluanalysis\",\"data\",\"processed_data.rds\")\nexp_data=readRDS(file=data_location)\n```\n:::\n\n\n## Data Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n# data splitting\nbodytemp_split=initial_split(exp_data,prop=0.7,strata = BodyTemp)\nbodytemp_train=training(bodytemp_split)\nbodytemp_test=testing(bodytemp_split)\n# data re-sampling using cross-validation\nbodytemp_folds=vfold_cv(bodytemp_train,v=5,repeats = 5,strata = BodyTemp)\n# Create a recipe\nbodytemp_rec=recipe(BodyTemp~.,data=bodytemp_train)%>%\n  step_dummy(all_nominal(),-Weakness,-CoughIntensity,-Myalgia)%>%\n  step_mutate(Weakness = factor(Weakness, levels = c(\"None\",\"Mild\",\"Moderate\",\"Severe\"), ordered = TRUE),\n              CoughIntensity= factor(CoughIntensity, levels = c(\"None\",\"Mild\",\"Moderate\",\"Severe\"), ordered = TRUE),\n              Myalgia=factor(Myalgia, levels = c(\"None\",\"Mild\",\"Moderate\",\"Severe\"), ordered = TRUE)) %>%\n  step_ordinalscore(Weakness, CoughIntensity, Myalgia)%>%\n  step_nzv(all_predictors(),unique_cut = 50)\n```\n:::\n\n\n## Creating workflow without models\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbodytemp_wf=workflow()%>%\n  add_recipe(bodytemp_rec)\n```\n:::\n\n\n## Null model performance\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_regression <- null_model() %>%\n  set_engine(\"parsnip\") %>%\n  set_mode(\"regression\")\n\nnull_rs <- fit_resamples(\n bodytemp_wf %>% add_model(null_regression),\n  bodytemp_folds,\n  metrics = metric_set(rmse),\n control=control_resamples(save_pred = TRUE)\n)\n\nnull_rs%>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard    1.21    25  0.0177 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Model specification for three models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decision Tree\ntree_spec=decision_tree(\n  cost_complexity = tune(),\n  tree_depth=tune()\n  )%>%\n  set_engine(\"rpart\")%>%\n  set_mode(\"regression\")\n# LASSO\nglm_spec=linear_reg(penalty=tune(),mixture=1)%>%\n  set_engine(\"glmnet\")\n\n# Random forest\ncores <- parallel::detectCores()\nrf_spec=\n  rand_forest(mtry=tune(),min_n=tune(),trees=1000)%>%\n  set_engine(\"ranger\",num.threads=cores)%>%\n  set_mode(\"regression\")\n```\n:::\n\n\n## Creating workflow for each model\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decision Tree\ntree_wf=bodytemp_wf%>%\n  add_model(tree_spec)\n# LASSO\nglm_wf=bodytemp_wf%>%\n  add_model(glm_spec)\n# Random forest\nrf_wf=bodytemp_wf%>%\n  add_model(rf_spec)\n```\n:::\n\n\n## Creating regular grid of values for each hyperparameters in three models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decision Tree\ntree_grid=grid_regular(cost_complexity(),\n                       tree_depth(),\n                       levels=5)\ntree_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             <dbl>      <int>\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# … with 15 more rows\n```\n:::\n\n```{.r .cell-code}\n# LASSO\nglm_grid=tibble(penalty=10^seq(-4,-1,length.out=30))\nglm_grid%>%\n  top_n(-5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by penalty\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n```\n:::\n\n```{.r .cell-code}\nglm_grid%>%\n  top_n(5)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by penalty\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 1\n  penalty\n    <dbl>\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n```\n:::\n\n```{.r .cell-code}\n# Random forest\n# using a space-filling design to tune later\n```\n:::\n\n\n## Train and tune the models\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decision Tree\ntree_rs=tree_wf%>%\n  tune_grid(\n    resamples=bodytemp_folds,\n    grid=tree_grid\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold1, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold2, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold3, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold4, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold5, Repeat1: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold1, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold2, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold3, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold4, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold5, Repeat2: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold1, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold2, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold3, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold4, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold5, Repeat3: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold1, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold2, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold3, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold4, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold5, Repeat4: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold1, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold2, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold3, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold4, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n! Fold5, Repeat5: internal:\n  There was 1 warning in `dplyr::summarise()`.\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 1`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 4`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 8`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 11`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n  ℹ In argument: `.estimate = metric_fn(truth = BodyTemp, estimate = .pr...\n    = na_rm)`.\n  ℹ In group 1: `cost_complexity = 0.1`, `tree_depth = 15`.\n  Caused by warning:\n  ! A correlation computation is required, but `estimate` is constant an...\n```\n:::\n\n```{.r .cell-code}\ntree_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 5\n   splits            id      id2   .metrics          .notes          \n   <list>            <chr>   <chr> <list>            <list>          \n 1 <split [405/103]> Repeat1 Fold1 <tibble [50 × 6]> <tibble [1 × 3]>\n 2 <split [405/103]> Repeat1 Fold2 <tibble [50 × 6]> <tibble [1 × 3]>\n 3 <split [406/102]> Repeat1 Fold3 <tibble [50 × 6]> <tibble [1 × 3]>\n 4 <split [408/100]> Repeat1 Fold4 <tibble [50 × 6]> <tibble [1 × 3]>\n 5 <split [408/100]> Repeat1 Fold5 <tibble [50 × 6]> <tibble [1 × 3]>\n 6 <split [405/103]> Repeat2 Fold1 <tibble [50 × 6]> <tibble [1 × 3]>\n 7 <split [405/103]> Repeat2 Fold2 <tibble [50 × 6]> <tibble [1 × 3]>\n 8 <split [406/102]> Repeat2 Fold3 <tibble [50 × 6]> <tibble [1 × 3]>\n 9 <split [408/100]> Repeat2 Fold4 <tibble [50 × 6]> <tibble [1 × 3]>\n10 <split [408/100]> Repeat2 Fold5 <tibble [50 × 6]> <tibble [1 × 3]>\n# … with 15 more rows\n\nThere were issues with some computations:\n\n  - Warning(s) x25: There was 1 warning in `dplyr::summarise()`. ℹ In argument: `.est...\n\nRun `show_notes(.Last.tune.result)` for more information.\n```\n:::\n\n```{.r .cell-code}\n# LASSO\nglm_rs=glm_wf%>%\n  tune_grid(\n    resamples=bodytemp_folds,\n    grid=glm_grid,\n    control=control_grid(save_pred = TRUE),\n    metrics=metric_set(rmse)\n  )\nglm_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 6\n   splits            id      id2   .metrics          .notes           .predict…¹\n   <list>            <chr>   <chr> <list>            <list>           <list>    \n 1 <split [405/103]> Repeat1 Fold1 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 2 <split [405/103]> Repeat1 Fold2 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 3 <split [406/102]> Repeat1 Fold3 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 4 <split [408/100]> Repeat1 Fold4 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 5 <split [408/100]> Repeat1 Fold5 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 6 <split [405/103]> Repeat2 Fold1 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 7 <split [405/103]> Repeat2 Fold2 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 8 <split [406/102]> Repeat2 Fold3 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n 9 <split [408/100]> Repeat2 Fold4 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n10 <split [408/100]> Repeat2 Fold5 <tibble [30 × 5]> <tibble [0 × 3]> <tibble>  \n# … with 15 more rows, and abbreviated variable name ¹​.predictions\n```\n:::\n\n```{.r .cell-code}\n# Random forest\nrf_rs=rf_wf%>%\n  tune_grid(\n    resamples=bodytemp_folds,\n    grid=25,\n    control=control_grid(save_pred=TRUE),\n    metrics = metric_set(rmse)\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\nrf_rs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 5-fold cross-validation repeated 5 times using stratification \n# A tibble: 25 × 6\n   splits            id      id2   .metrics          .notes           .predict…¹\n   <list>            <chr>   <chr> <list>            <list>           <list>    \n 1 <split [405/103]> Repeat1 Fold1 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 2 <split [405/103]> Repeat1 Fold2 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 3 <split [406/102]> Repeat1 Fold3 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 4 <split [408/100]> Repeat1 Fold4 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 5 <split [408/100]> Repeat1 Fold5 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 6 <split [405/103]> Repeat2 Fold1 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 7 <split [405/103]> Repeat2 Fold2 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 8 <split [406/102]> Repeat2 Fold3 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n 9 <split [408/100]> Repeat2 Fold4 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n10 <split [408/100]> Repeat2 Fold5 <tibble [25 × 6]> <tibble [0 × 3]> <tibble>  \n# … with 15 more rows, and abbreviated variable name ¹​.predictions\n```\n:::\n:::\n\n\n## Evaluate the performance and finalize the model\n\n### Decision trees\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting the result\ntree_rs%>%\nautoplot()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Selecting the best tuning parameter based on rmse\nbest_tree=tree_rs%>%\n  select_best(\"rmse\")\n# Finalize the workflow\ntree_final=\n  tree_wf%>%\n  finalize_workflow(best_tree)\ntree_final\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_dummy()\n• step_mutate()\n• step_ordinalscore()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (regression)\n\nMain Arguments:\n  cost_complexity = 1e-10\n  tree_depth = 1\n\nComputational engine: rpart \n```\n:::\n\n```{.r .cell-code}\n# Fitting training data\ntree_fit=tree_final%>%\n  fit(bodytemp_train)\n# Predicted value\ntree_predict=tree_final%>%\n  fit(bodytemp_train)%>%\n  predict(bodytemp_train)\ntree_predict\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 508 × 1\n   .pred\n   <dbl>\n 1  99.2\n 2  99.2\n 3  98.7\n 4  98.7\n 5  98.7\n 6  98.7\n 7  98.7\n 8  99.2\n 9  99.2\n10  99.2\n# … with 498 more rows\n```\n:::\n\n```{.r .cell-code}\n# Plotting the true values vs predicted values\nbodytemp_train%>%\n  select(BodyTemp)%>%\n  bind_cols(tree_predict)%>%\n  ggplot(aes(BodyTemp,.pred))+\n  geom_jitter()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting the residuals\n# Calculate residuals\ntree_resid <- bodytemp_train$BodyTemp - tree_predict\n# Create a data frame with the residuals and predicted values\nresid_df_tree <- data.frame(tree_resid, tree_predict)\ncolnames(resid_df_tree) <- c(\"residuals\", \"predicted_values\")\n# Draw the residual plot\nggplot(resid_df_tree, aes(x = predicted_values,y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(x=\"Predicted values\",y=\"Residuals\",title=\"Residual Plot for Decision Tree Model\") \n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-10-3.png){width=672}\n:::\n\n```{.r .cell-code}\nrpart.plot(extract_fit_parsnip(tree_fit)$fit)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Cannot retrieve the data used to build the model (so cannot determine roundint and is.binary for the variables).\nTo silence this warning:\n    Call rpart.plot with roundint=FALSE,\n    or rebuild the rpart model with model=TRUE.\n```\n:::\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-10-4.png){width=672}\n:::\n:::\n\n\n### LASSO\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting the result\nglm_rs%>%\nautoplot()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# show the best tuning parameter\nglm_rs%>%\n show_best(\"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1  0.0489 rmse    standard    1.15    25  0.0170 Preprocessor1_Model27\n2  0.0621 rmse    standard    1.15    25  0.0170 Preprocessor1_Model28\n3  0.0386 rmse    standard    1.15    25  0.0170 Preprocessor1_Model26\n4  0.0788 rmse    standard    1.15    25  0.0171 Preprocessor1_Model29\n5  0.0304 rmse    standard    1.15    25  0.0170 Preprocessor1_Model25\n```\n:::\n\n```{.r .cell-code}\n# Selecting the best tuning parameter based on rmse\nbest_glm=glm_rs%>%\n  select_best(\"rmse\")\nbest_glm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n  penalty .config              \n    <dbl> <chr>                \n1  0.0489 Preprocessor1_Model27\n```\n:::\n\n```{.r .cell-code}\n# Finalize the workflow\nglm_final=\n  glm_wf%>%\n  finalize_workflow(best_glm)\n# Fitting training data\nglm_fit=glm_final%>%\n  fit(bodytemp_train)\n# Predicted value\nglm_predict=glm_final%>%\n  fit(bodytemp_train)%>%\n  predict(bodytemp_train)\nglm_predict\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 508 × 1\n   .pred\n   <dbl>\n 1  98.7\n 2  98.8\n 3  98.5\n 4  98.9\n 5  98.7\n 6  98.7\n 7  98.3\n 8  99.3\n 9  98.9\n10  98.9\n# … with 498 more rows\n```\n:::\n\n```{.r .cell-code}\n# Plotting the true values vs predicted values\nbodytemp_train%>%\n  select(BodyTemp)%>%\n  bind_cols(glm_predict)%>%\n  ggplot(aes(BodyTemp,.pred))+\n  geom_jitter()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-11-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Residuals analysis\n# Calculate residuals\nglm_resid <- bodytemp_train$BodyTemp - glm_predict\n# Create a data frame with the residuals and predicted values\nresid_df_glm <- data.frame(glm_resid, glm_predict)\ncolnames(resid_df_glm) <- c(\"residuals\", \"predicted_values\")\n# Draw the residual plot\nggplot(resid_df_glm, aes(x = predicted_values,y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(x=\"Predicted values\",y=\"Residuals\",title=\"Residual Plot for GLM Model\") \n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-11-3.png){width=672}\n:::\n\n```{.r .cell-code}\nx=glm_fit$fit$fit$fit\nplot(x,\"lambda\")\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-11-4.png){width=672}\n:::\n:::\n\n\n### Random forest\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# plotting the result\nrf_rs%>%\nautoplot()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# show the best tuning parameter\nrf_rs%>%\n show_best(\"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     3    18 rmse    standard    1.16    25  0.0169 Preprocessor1_Model16\n2     5    21 rmse    standard    1.16    25  0.0167 Preprocessor1_Model22\n3     4    15 rmse    standard    1.16    25  0.0168 Preprocessor1_Model18\n4     6    31 rmse    standard    1.16    25  0.0166 Preprocessor1_Model19\n5     2    16 rmse    standard    1.16    25  0.0169 Preprocessor1_Model15\n```\n:::\n\n```{.r .cell-code}\n# Selecting the best tuning parameter based on rmse\nbest_rf=rf_rs%>%\n  select_best(\"rmse\")\nbest_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     3    18 Preprocessor1_Model16\n```\n:::\n\n```{.r .cell-code}\n# Finalize the workflow\nrf_final=\n  rf_wf%>%\n  finalize_workflow(best_rf)\nrf_final\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n4 Recipe Steps\n\n• step_dummy()\n• step_mutate()\n• step_ordinalscore()\n• step_nzv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  mtry = 3\n  trees = 1000\n  min_n = 18\n\nEngine-Specific Arguments:\n  num.threads = cores\n\nComputational engine: ranger \n```\n:::\n\n```{.r .cell-code}\n# Fitting training data\nrf_fit=rf_final%>%\n  fit(bodytemp_train)\n# Predicted value\nrf_predict=glm_final%>%\n  fit(bodytemp_train)%>%\n  predict(bodytemp_train)\nrf_predict\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 508 × 1\n   .pred\n   <dbl>\n 1  98.7\n 2  98.8\n 3  98.5\n 4  98.9\n 5  98.7\n 6  98.7\n 7  98.3\n 8  99.3\n 9  98.9\n10  98.9\n# … with 498 more rows\n```\n:::\n\n```{.r .cell-code}\n# Plotting the true values vs predicted values\nbodytemp_train%>%\n  select(BodyTemp)%>%\n  bind_cols(rf_predict)%>%\n  ggplot(aes(BodyTemp,.pred))+\n  geom_jitter()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting the residuals\n# Calculate residuals\nrf_resid <- bodytemp_train$BodyTemp - rf_predict\n# Create a data frame with the residuals and predicted values\nresid_df_rf <- data.frame(rf_resid, rf_predict)\ncolnames(resid_df_rf) <- c(\"residuals\", \"predicted_values\")\n# Draw the residual plot\nggplot(resid_df_rf, aes(x = predicted_values,y = residuals)) +\n  geom_point() +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  labs(x=\"Predicted values\",y=\"Residuals\",title=\"Residual Plot for Random Forest Model\")\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-12-3.png){width=672}\n:::\n:::\n\n\n## Compare three models with the null model\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_metrics=tree_rs%>%\n show_best(\"rmse\")%>%\n  filter(.config==\"Preprocessor1_Model01\")\nglm_metrics=glm_rs%>%\n show_best(\"rmse\")%>%\n  filter(.config==\"Preprocessor1_Model27\")\nrf_metrics=rf_rs%>%\n show_best(\"rmse\")%>%\n  filter(.config==\"Preprocessor1_Model22\")\nnull_rs%>%\n  collect_metrics()%>%\n  mutate(model=\"Null\")%>%\n  bind_rows(tree_metrics%>%\n              mutate(model=\"tree\"),\n            glm_metrics%>%\n              mutate(model=\"LASSO\"),\n            rf_metrics%>%\n              mutate(model=\"random forest\")\n    \n  )%>%\n  select(c(1:6),model)%>%\n  kable()\n```\n\n::: {.cell-output-display}\n|.metric |.estimator |     mean|  n|   std_err|.config               |model         |\n|:-------|:----------|--------:|--:|---------:|:---------------------|:-------------|\n|rmse    |standard   | 1.206661| 25| 0.0176723|Preprocessor1_Model1  |Null          |\n|rmse    |standard   | 1.189406| 25| 0.0180607|Preprocessor1_Model01 |tree          |\n|rmse    |standard   | 1.151382| 25| 0.0169964|Preprocessor1_Model27 |LASSO         |\n|rmse    |standard   | 1.160807| 25| 0.0167077|Preprocessor1_Model22 |random forest |\n:::\n:::\n\n\n## Final model selection\n\n### After comparing four models, LASSO model is the best model since it has the lowest rmse. Although the standard error is a bit higher than that of random forest.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm_fit_final=glm_final%>%\n  last_fit(bodytemp_split)\nglm_fit_final%>%\n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard      1.16   Preprocessor1_Model1\n2 rsq     standard      0.0312 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\nglm_predict_final=glm_fit_final%>%\n  collect_predictions()\nglm_fit_final%>%\n  extract_fit_engine()%>%\n  vip()\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting the true values vs predicted values\nglm_predict_final%>%\n  ggplot(aes(BodyTemp,.pred))+\n  geom_jitter()+\n  geom_smooth()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-14-2.png){width=672}\n:::\n\n```{.r .cell-code}\n## Plot residuals\nfinal_resid=glm_predict_final$BodyTemp-glm_predict_final$.pred\nfinal_resid_df=data.frame(final_resid,glm_predict_final$.pred)\ncolnames(final_resid_df)=c(\"residuals\", \"predicted_values\")\nggplot(final_resid_df,aes(predicted_values,residuals))+\n  geom_point()+\n  geom_hline(yintercept=0,linetype=\"dashed\")+\n   labs(x=\"Predicted values\",y=\"Residuals\",title=\"Residual Plot for Final Model LASSO\")\n```\n\n::: {.cell-output-display}\n![](machinelearning_files/figure-html/unnamed-chunk-14-3.png){width=672}\n:::\n:::\n\n\n## In conclusion, the best model LASSO has rmse of 1.155 when it fits testing data. The residuals seems to be randomly distributed on the residual plot\n",
    "supporting": [
      "machinelearning_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}